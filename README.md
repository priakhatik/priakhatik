# üëã Hi, I‚Äôm Pria Khatik

üìç Tampa, FL, USA  
üìß priakhatik@gmail.com
üîó LinkedIn ‚Ä¢ GitHub  

![AWS](https://img.shields.io/badge/AWS%20Certified%20Data%20Engineer-232F3E?style=for-the-badge&logo=amazonaws&logoColor=white)
![Fabric](https://img.shields.io/badge/Microsoft%20Fabric%20Data%20Engineer-0078D4?style=for-the-badge&logo=microsoft&logoColor=white)
![Databricks Data Engineer](https://img.shields.io/badge/Databricks%20Data%20Engineer-FF3621?style=for-the-badge&logo=databricks&logoColor=white)

---

## üöÄ About Me

I‚Äôm a **Data Analytics Engineer** with 4+ years of experience building scalable data pipelines, analytics solutions, and business intelligence systems that turn raw data into actionable insights.

Currently pursuing my **Master‚Äôs in Artificial Intelligence & Business Analytics at the University of South Florida**, I combine strong foundations in data engineering, data warehousing, and advanced analytics with real-world industry experience.

At **Sarasota County Government**, I analyze fleet operations for 1,000+ vehicles, supporting a **$12M+ replacement budget** through SQL-driven analysis, data modeling, and Power BI dashboards that directly influence operational and financial decisions.

Previously at **Accenture**, I partnered with product and analytics teams to design and optimize **ETL pipelines using Python and SQL** across **GCP and Snowflake**, built **star and snowflake schemas**, and delivered BI solutions that improved data freshness, reporting efficiency, and decision-making speed at scale.

My work spans **data pipelines, dimensional modeling, analytics engineering, and BI**, with a strong focus on data quality, scalability, and measurable business impact.

---

## üíº Experience

### üèõÔ∏è Data Analyst Intern | Sarasota County Government  
**May 2025 ‚Äì Present**
- Analyzed fleet operations for **1,000+ vehicles**, optimizing a **$12M+ replacement budget** and identifying **15% potential cost savings**  
- Cleaned, modeled, and validated **500K+ rows of data** using Excel and SQL, saving **20+ hours per week** through automation  
- Built interactive **Power BI dashboards** tracking utilization and KPIs, reducing manual reporting by **70%**  
- Supported multi-year replacement planning using **Asana**, improving forecast accuracy by **10%**  
- Identified underutilized assets and implemented cost-recovery measures, recovering **$50K+** through reallocation  

### üè¢ Data Engineer | Accenture  
**Nov 2019 ‚Äì Jul 2024**
- Built automated data pipelines using **Python (Pandas, NumPy)** and **SQL**, ensuring reliability and scalability across analytics systems  
- Designed and optimized **ETL workflows** in **BigQuery and Snowflake**, improving data freshness and query performance by **40%**  
- Developed **star and snowflake schemas** integrating CRM, operations, and usage data within GCP  
- Delivered **Tableau and Power BI dashboards** consolidating multi-source data, cutting manual reporting by **50%**  
- Performed trend and adoption analysis on **1TB+ datasets**, supporting release planning and feature optimization  
- Established data quality and validation frameworks, improving data consistency by **35%**  
- Mentored junior analysts and led automation initiatives, improving team throughput by **25%**

---

## üß© Featured Projects

### üé¨ Netflix ‚Äì Streaming Analytics Data Platform
**Tech:** AWS S3 ‚Ä¢ Databricks (PySpark) ‚Ä¢ Snowflake ‚Ä¢ dbt ‚Ä¢ Apache Airflow ‚Ä¢ SQL

- Ingested raw user viewing events and content metadata into an AWS S3 data lake
- Used Databricks (PySpark) for large-scale batch transformations and session-level aggregations
- Loaded curated datasets into Snowflake for analytics and reporting
- Built fact and dimension tables using dbt with tests, documentation, and lineage
- Orchestrated end-to-end pipelines using Apache Airflow
- Enabled analytics use cases such as content performance, user engagement, and retention analysis

---

### üöó Tesla ‚Äì Vehicle Telemetry & Fleet Analytics Platform
**Tech:** Azure Data Lake ‚Ä¢ Databricks (Spark) ‚Ä¢ Snowflake ‚Ä¢ dbt ‚Ä¢ SQL ‚Ä¢ Power BI

- Ingested high-volume vehicle telemetry and maintenance data into Azure Data Lake
- Processed and aggregated time-series telemetry data using Databricks and Apache Spark
- Modeled analytics-ready tables in Snowflake to track vehicle health, utilization, and failures
- Applied dbt for standardized transformations and KPI definitions
- Built Power BI dashboards to support predictive maintenance and fleet optimization decisions

---

### üîê Cybersecurity ‚Äì Security Log Analytics & Threat Detection Pipeline
**Tech:** GCP Cloud Storage ‚Ä¢ Databricks (Spark) ‚Ä¢ Snowflake ‚Ä¢ SQL ‚Ä¢ Apache Airflow

- Collected authentication logs and network security events into GCP Cloud Storage
- Used Databricks and Spark to process high-volume log data and engineer security features
- Stored historical security events and alerts in Snowflake for analytical querying
- Automated ingestion and transformation workflows using Apache Airflow
- Built analytical queries to identify anomaly patterns and support security investigations

---

### ü§ñ LLM-Powered Analytics Engineering Assistant
**Tech:** Python ‚Ä¢ LLMs ‚Ä¢ Snowflake ‚Ä¢ dbt ‚Ä¢ Apache Airflow ‚Ä¢ AWS

- Built an LLM-powered assistant to translate business questions into validated SQL queries
- Connected the LLM layer to Snowflake metadata and analytics tables
- Used dbt models as the governed transformation layer to ensure consistent metrics
- Integrated query validation and schema checks before execution
- Orchestrated LLM workflows and dbt runs using Apache Airflow
- Improved analyst productivity by accelerating data exploration and ad-hoc analytics

---

## üõ†Ô∏è Technical Skills

### üë©‚Äçüíª Programming & Querying
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-CC2927?style=for-the-badge&logo=postgresql&logoColor=white)
![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)
![R](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white)

### üìä Data & Analytics
![Data Cleaning](https://img.shields.io/badge/Data%20Cleaning-111827?style=for-the-badge)
![Data Modeling](https://img.shields.io/badge/Data%20Modeling-111827?style=for-the-badge)
![Data Warehousing](https://img.shields.io/badge/Data%20Warehousing-111827?style=for-the-badge)
![OLAP](https://img.shields.io/badge/OLAP-111827?style=for-the-badge)
![Advanced Analytics](https://img.shields.io/badge/Advanced%20Analytics-111827?style=for-the-badge)
![Machine Learning](https://img.shields.io/badge/Machine%20Learning-111827?style=for-the-badge&logo=scikitlearn&logoColor=white)

### ‚òÅÔ∏è Cloud & Big Data
![AWS](https://img.shields.io/badge/AWS-232F3E?style=for-the-badge&logo=amazonaws&logoColor=white)
![GCP](https://img.shields.io/badge/GCP-4285F4?style=for-the-badge&logo=googlecloud&logoColor=white)
![Azure](https://img.shields.io/badge/Azure-0078D4?style=for-the-badge&logo=microsoftazure&logoColor=white)
![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?style=for-the-badge&logo=snowflake&logoColor=white)
![BigQuery](https://img.shields.io/badge/BigQuery-4285F4?style=for-the-badge&logo=googlebigquery&logoColor=white)
![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=apacheairflow&logoColor=white)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)
![Hadoop](https://img.shields.io/badge/Hadoop-66CCFF?style=for-the-badge&logo=apachehadoop&logoColor=black)

### üóÉÔ∏è Databases
![BigQuery](https://img.shields.io/badge/BigQuery-4285F4?style=for-the-badge&logo=googlebigquery&logoColor=white)
![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?style=for-the-badge&logo=snowflake&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=for-the-badge&logo=postgresql&logoColor=white)
![MySQL](https://img.shields.io/badge/MySQL-4479A1?style=for-the-badge&logo=mysql&logoColor=white)
![SQL Server](https://img.shields.io/badge/SQL%20Server-CC2927?style=for-the-badge&logo=microsoftsqlserver&logoColor=white)

### üß∞ Tools & BI
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?style=for-the-badge&logo=powerbi&logoColor=black)
![Tableau](https://img.shields.io/badge/Tableau-E97627?style=for-the-badge&logo=tableau&logoColor=white)
![Looker](https://img.shields.io/badge/Looker-4285F4?style=for-the-badge&logo=looker&logoColor=white)
![Excel](https://img.shields.io/badge/Excel-217346?style=for-the-badge&logo=microsoftexcel&logoColor=white)
![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)
![Asana](https://img.shields.io/badge/Asana-F06A6A?style=for-the-badge&logo=asana&logoColor=white)

---

## üìú Certifications

üéì **AWS Certified Data Engineer ‚Äì Associate**  
üéì **Microsoft Fabric Data Engineer Associate**  
üéì **Google Professional Data Engineer**

---

## ü§ù Let‚Äôs Connect

I‚Äôm passionate about building **scalable data systems, analytics platforms, and BI solutions** that drive real business impact.

Feel free to explore my repositories, connect on LinkedIn, or reach out for collaboration.

üìß Email: priyakhatik@usf.edu  
üîó LinkedIn: https://www.linkedin.com/in/priyakhatik  
üíª GitHub: https://github.com/priakhatik
